{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Poisoning Demo with Gradio\n",
    "\n",
    "##This notebook creates an interactive interface for image poisoning using Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_hemlock_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-03 19:24:04.559730: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image):\n",
    "    \"\"\"Load and preprocess an image for the model.\"\"\"\n",
    "    # Convert to PIL Image if it's a numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        img = Image.fromarray(image)\n",
    "    else:\n",
    "        img = image\n",
    "        \n",
    "    # Resize image while maintaining aspect ratio\n",
    "    target_size = (224, 224)\n",
    "    img.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Create a new image with padding\n",
    "    new_img = Image.new('RGB', target_size, (0, 0, 0))\n",
    "    offset = ((target_size[0] - img.size[0]) // 2,\n",
    "              (target_size[1] - img.size[1]) // 2)\n",
    "    new_img.paste(img, offset)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(new_img)\n",
    "    \n",
    "    # Ensure the image is in RGB format\n",
    "    if len(img_array.shape) == 2:  # Grayscale\n",
    "        img_array = np.stack([img_array] * 3, axis=-1)\n",
    "    elif img_array.shape[2] == 4:  # RGBA\n",
    "        img_array = img_array[:, :, :3]\n",
    "        \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_pattern(input_image, input_label, model, epsilon):\n",
    "    \"\"\"Create an adversarial pattern using FGSM with improved gradient computation.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model(input_image)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(input_label, prediction)\n",
    "    \n",
    "    # Get the gradients of the loss with respect to the input image\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    \n",
    "    # Apply gradient smoothing\n",
    "    gradient = gaussian_filter(gradient.numpy(), sigma=1.0)\n",
    "    gradient = tf.convert_to_tensor(gradient)\n",
    "    \n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    # Create the adversarial pattern with improved scaling\n",
    "    perturbation = epsilon * signed_grad\n",
    "    \n",
    "    return perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation(image, epsilon):\n",
    "    \"\"\"Apply perturbation to the image with improved preprocessing and scaling.\"\"\"\n",
    "    # Store original image for reference\n",
    "    original = image.copy()\n",
    "    \n",
    "    # Preprocess the image for the model\n",
    "    preprocessed = preprocess_input(image)\n",
    "    preprocessed = np.expand_dims(preprocessed, axis=0)\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    predictions = model.predict(preprocessed)\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    \n",
    "    # Create adversarial pattern\n",
    "    perturbation = create_adversarial_pattern(\n",
    "        tf.convert_to_tensor(preprocessed),\n",
    "        tf.convert_to_tensor([predicted_label]),\n",
    "        model,\n",
    "        epsilon\n",
    "    )\n",
    "    \n",
    "    # Apply the perturbation with improved scaling\n",
    "    perturbed = preprocessed + perturbation.numpy()\n",
    "    \n",
    "    # Convert back to original scale with proper denormalization\n",
    "    perturbed = perturbed[0]  # Remove batch dimension\n",
    "    perturbed = (perturbed + 1) * 127.5  # Denormalize from [-1, 1] to [0, 255]\n",
    "    \n",
    "    # Apply adaptive thresholding based on epsilon\n",
    "    if epsilon > 0:\n",
    "        threshold = 127.5 * epsilon\n",
    "        perturbed = np.where(np.abs(perturbed - original) > threshold, perturbed, original)\n",
    "    \n",
    "    # Clip to valid range\n",
    "    perturbed = np.clip(perturbed, 0, 255)\n",
    "    \n",
    "    return perturbed, predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def process_image(image, epsilon):\n",
    "    \"\"\"Process the image and return both original and perturbed versions.\"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        image_array = load_and_preprocess_image(image)\n",
    "        \n",
    "        # Get original prediction\n",
    "        preprocessed = preprocess_input(image_array.reshape(1, 224, 224, 3))\n",
    "        original_pred = model.predict(preprocessed)\n",
    "        original_label = decode_predictions(original_pred, top=1)[0][0][1]\n",
    "        \n",
    "        # Apply perturbation with epsilon scaling\n",
    "        perturbed_image, _ = apply_perturbation(image_array, epsilon)\n",
    "        \n",
    "        # Get perturbed prediction\n",
    "        preprocessed_perturbed = preprocess_input(perturbed_image.reshape(1, 224, 224, 3))\n",
    "        perturbed_pred = model.predict(preprocessed_perturbed)\n",
    "        perturbed_label = decode_predictions(perturbed_pred, top=1)[0][0][1]\n",
    "        \n",
    "        # Create figure with both images\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        \n",
    "        # Display original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_array)\n",
    "        plt.title(f\"Original Image\\nClass: {original_label}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display perturbed image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(perturbed_image.astype(np.uint8))\n",
    "        plt.title(f\"Perturbed Image (ε={epsilon:.2f})\\nClass: {perturbed_label}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure to a temporary file\n",
    "        plt.savefig('temp_result.png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        \n",
    "        return 'temp_result.png'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_image,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"Upload an image\"),\n",
    "        gr.Slider(minimum=0.0, maximum=0.5, value=0.1, step=0.01, label=\"Perturbation Strength (ε)\")\n",
    "    ],\n",
    "    outputs=gr.Image(label=\"Results\"),\n",
    "    title=\"Image Poisoning Demo\",\n",
    "    description=\"Upload an image and adjust the perturbation strength to see how it affects the model's classification.\",\n",
    "    examples=[\n",
    "        [\"example1.jpg\", 0.1],\n",
    "        [\"example2.jpg\", 0.2]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################Next Cell is Test Cell#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_hemlock_env/lib/python3.12/site-packages/gradio/blocks.py:1115: UserWarning: Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-67ef1b80-7dbae58741ce6474419075bb;1f4b8779-7c78-4ce4-9e31-51a23ba77e0c)\n",
      "\n",
      "Sorry, we can't find the page you are looking for.\n",
      "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Importing Required Libraries and Setting Up the Model\n",
    "# This cell imports all necessary libraries and loads the MobileNetV2 model\n",
    "# with pre-trained weights from ImageNet.\n",
    "\n",
    "# Import Gradio for creating the web interface\n",
    "import gradio as gr\n",
    "# Import TensorFlow for deep learning operations\n",
    "import tensorflow as tf\n",
    "# Import NumPy for numerical operations\n",
    "import numpy as np\n",
    "# Import PIL for image processing\n",
    "from PIL import Image\n",
    "# Import OpenCV for advanced image operations\n",
    "import cv2\n",
    "# Import MobileNetV2 model and its preprocessing functions\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "# Import Matplotlib for creating visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MobileNetV2 model with pre-trained weights\n",
    "model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "# Cell 2: Image Preprocessing Function\n",
    "# This function handles loading and preprocessing of input images\n",
    "# to ensure they're in the correct format for the model.\n",
    "\n",
    "def load_and_preprocess_image(image):\n",
    "    \"\"\"Load and preprocess an image while preserving original values.\"\"\"\n",
    "    # Create a copy of the input image if it's already a numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        img_array = image.copy()\n",
    "    else:\n",
    "        # Convert PIL image to numpy array\n",
    "        img_array = np.array(image)\n",
    "    \n",
    "    # Convert grayscale images to RGB by repeating the channel\n",
    "    if len(img_array.shape) == 2:\n",
    "        img_array = np.stack([img_array] * 3, axis=-1)\n",
    "    # Remove alpha channel if present\n",
    "    elif img_array.shape[2] == 4:\n",
    "        img_array = img_array[:, :, :3]\n",
    "    \n",
    "    # Resize image to 224x224 (required by MobileNetV2)\n",
    "    return cv2.resize(img_array, (224, 224))\n",
    "\n",
    "# Cell 3: Adversarial Example Generation\n",
    "# This function creates adversarial examples using the Fast Gradient Sign Method (FGSM)\n",
    "# by computing gradients of the loss with respect to the input image.\n",
    "\n",
    "def generate_adversarial(image, epsilon):\n",
    "    \"\"\"Generate adversarial example using FGSM.\"\"\"\n",
    "    # Convert image to tensor and add batch dimension\n",
    "    image_tensor = tf.convert_to_tensor(image)\n",
    "    image_tensor = tf.cast(image_tensor, tf.float32)\n",
    "    image_tensor = tf.expand_dims(image_tensor, 0)\n",
    "    \n",
    "    # Compute gradients using gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Watch the input tensor for gradient computation\n",
    "        tape.watch(image_tensor)\n",
    "        # Preprocess image for the model\n",
    "        preprocessed = preprocess_input(image_tensor)\n",
    "        # Get model prediction\n",
    "        prediction = model(preprocessed, training=False)\n",
    "        # Get the predicted class\n",
    "        target_class = tf.argmax(prediction[0])\n",
    "        target_class = tf.cast(target_class, tf.int64)\n",
    "        # Compute loss\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()(\n",
    "            tf.expand_dims(target_class, 0), prediction\n",
    "        )\n",
    "    \n",
    "    # Get gradients of loss with respect to input\n",
    "    gradients = tape.gradient(loss, image_tensor)\n",
    "    # Create perturbation using sign of gradients\n",
    "    perturbation = epsilon * tf.sign(gradients)\n",
    "    # Apply perturbation to original image\n",
    "    adversarial_image = image_tensor + perturbation\n",
    "    # Clip values to valid range [0, 255]\n",
    "    adversarial_image = tf.clip_by_value(adversarial_image, 0, 255)\n",
    "    \n",
    "    # Return perturbed image as numpy array\n",
    "    return adversarial_image[0].numpy().astype(np.uint8)\n",
    "\n",
    "# Cell 4: Visualization Creation\n",
    "# This function creates a professional comparison visualization\n",
    "# showing original image, perturbed image, and the difference between them.\n",
    "\n",
    "def create_comparison_visualization(original, perturbed, orig_label, pert_label, orig_conf, pert_conf, epsilon):\n",
    "    \"\"\"Create a professional comparison visualization.\"\"\"\n",
    "    # Set dark theme for better visibility\n",
    "    plt.style.use('dark_background')\n",
    "    # Create figure with specific size\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Create grid for subplots\n",
    "    gs = plt.GridSpec(1, 3, width_ratios=[1, 1, 1], wspace=0.3)\n",
    "    \n",
    "    # Plot original image\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title(f\"Original\\n{orig_label}\\nConfidence: {orig_conf:.1f}%\", \n",
    "                 color='white', pad=10)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot perturbed image\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    ax2.imshow(perturbed)\n",
    "    ax2.set_title(f\"Perturbed (ε={epsilon:.3f})\\n{pert_label}\\nConfidence: {pert_conf:.1f}%\", \n",
    "                 color='white', pad=10)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Plot difference visualization\n",
    "    ax3 = plt.subplot(gs[2])\n",
    "    # Compute absolute difference between images\n",
    "    difference = cv2.absdiff(original, perturbed)\n",
    "    # Enhance difference visualization using colormap\n",
    "    difference = cv2.applyColorMap(\n",
    "        cv2.convertScaleAbs(difference, alpha=5), \n",
    "        cv2.COLORMAP_VIRIDIS\n",
    "    )\n",
    "    ax3.imshow(cv2.cvtColor(difference, cv2.COLOR_BGR2RGB))\n",
    "    ax3.set_title(\"Perturbation Map\\n(Enhanced Difference)\", \n",
    "                 color='white', pad=10)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # Set dark background\n",
    "    fig.patch.set_facecolor('#1A1A1A')\n",
    "    \n",
    "    # Save figure with specific settings\n",
    "    plt.savefig('temp_result.png', \n",
    "                bbox_inches='tight', \n",
    "                facecolor='#1A1A1A', \n",
    "                edgecolor='none', \n",
    "                pad_inches=0.2,\n",
    "                dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # Read and convert saved image\n",
    "    result_img = cv2.imread('temp_result.png', cv2.IMREAD_UNCHANGED)\n",
    "    return cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Cell 5: Main Processing Function\n",
    "# This function handles the entire image processing pipeline,\n",
    "# from loading the image to generating the final visualization.\n",
    "\n",
    "def process_image(image, epsilon):\n",
    "    \"\"\"Process image and return professional visualization.\"\"\"\n",
    "    try:\n",
    "        # Load and preprocess input image\n",
    "        original_image = load_and_preprocess_image(image)\n",
    "        \n",
    "        # Get prediction for original image\n",
    "        orig_preprocessed = preprocess_input(original_image[np.newaxis, ...].astype(np.float32))\n",
    "        orig_pred = model.predict(orig_preprocessed)\n",
    "        # Format label and get confidence\n",
    "        orig_label = decode_predictions(orig_pred, top=1)[0][0][1].replace('_', ' ').title()\n",
    "        orig_conf = float(orig_pred.max()) * 100\n",
    "        \n",
    "        # Handle epsilon=0 case\n",
    "        if epsilon == 0:\n",
    "            perturbed_image = original_image.copy()\n",
    "            pert_label = orig_label\n",
    "            pert_conf = orig_conf\n",
    "        else:\n",
    "            # Generate perturbed image\n",
    "            perturbed_image = generate_adversarial(original_image, epsilon)\n",
    "            # Get prediction for perturbed image\n",
    "            pert_preprocessed = preprocess_input(perturbed_image[np.newaxis, ...].astype(np.float32))\n",
    "            pert_pred = model.predict(pert_preprocessed)\n",
    "            # Format label and get confidence\n",
    "            pert_label = decode_predictions(pert_pred, top=1)[0][0][1].replace('_', ' ').title()\n",
    "            pert_conf = float(pert_pred.max()) * 100\n",
    "        \n",
    "        # Create final visualization\n",
    "        result = create_comparison_visualization(\n",
    "            original_image, perturbed_image,\n",
    "            orig_label, pert_label,\n",
    "            orig_conf, pert_conf,\n",
    "            epsilon\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Cell 6: Gradio Interface Creation\n",
    "# This cell creates the web interface using Gradio,\n",
    "# setting up the input and output components.\n",
    "\n",
    "# Create the Gradio interface with a professional dark theme\n",
    "iface = gr.Interface(\n",
    "    fn=process_image,  # Main processing function\n",
    "    inputs=[\n",
    "        gr.Image(type=\"numpy\", label=\"Upload Image\"),  # Image upload component\n",
    "        gr.Slider(minimum=0.0, maximum=0.1, value=0.0, step=0.005, \n",
    "                 label=\"Perturbation Strength (ε)\")  # Epsilon slider\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"numpy\", label=\"Analysis Results\"),  # Results display\n",
    "    title=\"Advanced Adversarial Image Analysis\",  # Interface title\n",
    "    description=\"Upload an image and adjust the perturbation strength to visualize how it affects MobileNetV2's classification. The rightmost panel shows an enhanced visualization of the perturbation pattern.\",\n",
    "    theme=\"dark\"  # Dark theme for better visibility\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_hemlock_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
